# Diffilm-Model
Text driven movie generation, Zero shot, based on the Diffusion model.

# Abstract
    Text to Video is a huge leap forward in the field of text generation and a new and challenging task. Currently, there are few related research achievements. This project utilizes deep learning technology and proposes a multimodal information processing model for story driven movie generation based on the diffusion model, Diffilm, for the first time. This model will train the T2I model based on text and image pairs, by modifying the spatiotemporal convolutional layer and attention layer, increasing the spatiotemporal dimension, and generating coherent movie scenes. Finally, the quality of the movie is enhanced through interpolation networks and hypercomponential networks. This project has the following three innovative points: firstly, the Diffilm model proposed in this project innovatively uses Zero shot to achieve a new idea of directly driving text to generate movies without the need for any images; Secondly, this project modifies the spatiotemporal convolutional layer and attention layer to increase the pseudo 3D spatiotemporal dimension, and generates coherent movie scenes with small parameter quantities; Thirdly, this project utilizes interpolation networks and super-resolution networks to enhance the coherence and clarity of movie images. The project has broad prospects and this new technology has economic value for the film industry; For some psychological or neurological diseases, such as heart blindness and Alzheimer's disease, this technology will also be widely applied in psychology and medical treatment by reconstructing brain images.

# Research contents
## Research objective
An intelligent model that can directly drive video generation from text
1. Learn what the world looks like
Description that matches the text image pair
2. Learn how the world moves
Unsupervised video sequence
3. Learn how to make this world high-definition
Frame Insertion Network and 2-layer Hyperdivision Network

## Research significance
(1) Realize one click conversion of stories into movies, creating a new way of intelligent generation.
(2) This technology can greatly reduce the cost of film production, improve the efficiency of filming, and has high economic value;
(2) This technology reconstructs brain images through descriptive text and has a wide range of applications in psychology and medicine.

# Innovation points and project characteristics
The innovative idea of using Zero shot to directly drive text to generate movies without the need for any images.
Add pseudo 3D spatiotemporal dimensions to generate coherent movie scenes with small parameter quantities. Accelerated the training process. Do not seek paired text video data.
Utilize interpolation networks and super-resolution networks to enhance the coherence and clarity of movie images. Improved training speed and quality.
